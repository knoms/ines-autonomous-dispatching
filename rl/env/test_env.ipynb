{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import gym\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from gym import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom.pulldom import parseString\n",
    "import numpy as np\n",
    "from StreetGraph import StreetGraph\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from datetime import datetime, timedelta\n",
    "from array import array\n",
    "\n",
    "class GraphEnv(gym.Env):\n",
    "\n",
    "    MAX_STEPS = 10\n",
    "\n",
    "    \n",
    "    def __init__(self,env_config = None):\n",
    "        env_config = env_config or {}\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            graph (nx.MultiDiGraph): graph\n",
    "            start_hub (int): nodeId\n",
    "            final_hub (int): nodeId\n",
    "\n",
    "        \"\"\"  \n",
    "        self.final_hub = 3\n",
    "        self.start_hub = 6\n",
    "        self.position = 6\n",
    "        \n",
    "        \n",
    "        pickup_day = 1\n",
    "        pickup_hour =  np.random.randint(24)\n",
    "        pickup_minute = np.random.randint(60)\n",
    "        self.pickup_time = datetime(2022,1,pickup_day,pickup_hour,pickup_minute,0)\n",
    "        self.time = self.pickup_time\n",
    "        self.total_travel_time = 0\n",
    "\n",
    "\n",
    "        self.graph =StreetGraph('meinheim')\n",
    "        self.graph.trips = StreetGraph('meinheim').trips\n",
    "\n",
    "\n",
    "        \n",
    "        self.seed()\n",
    "        self.reset()\n",
    "\n",
    "        # if self.graph.has_node(self.start_hub):\n",
    "        #     self.position = self.start_hub\n",
    "        # else:\n",
    "        #     return 'Initialized start hub was not found in graph'\n",
    "\n",
    "        # if self.graph.has_node(final_hub):\n",
    "        #     self.final_hub = final_hub\n",
    "        # else:\n",
    "        #     return 'Initialized final hub was not found in graph'\n",
    "        num_actions = len(self.availableActions())\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(num_actions) \n",
    "        self.observation_space = gym.spaces.Discrete(len(list(self.graph.graph.nodes()))) #num of nodes in the graph\n",
    "        \n",
    "\n",
    "    def step(self, action: int):\n",
    "        \"\"\" Executes an action based on the index passed as a parameter (only works with moves to direct neighbors as of now)\n",
    "\n",
    "        Args:\n",
    "            action (int): index of action to be taken from availableActions\n",
    "        Returns:\n",
    "            int: new position\n",
    "            int: new reward\n",
    "            boolean: isDone\n",
    "        \"\"\"\n",
    "        self.count += 1\n",
    "\n",
    "        old_position = list(self.graph.graph.nodes())[self.position]\n",
    "        availableActions = self.availableActions()\n",
    "        step_duration = 0\n",
    "\n",
    "        if self.validateAction(action):\n",
    "            if(action == 0):\n",
    "                step_duration = 300\n",
    "                pass\n",
    "            else:\n",
    "                selected_trip = availableActions[action-1]\n",
    "\n",
    "                if( list(self.graph.graph.nodes())[self.final_hub] in selected_trip['route']):\n",
    "                    route = selected_trip['route']\n",
    "\n",
    "                    self.position = self.final_hub\n",
    "                    index_in_route = route.index( list(self.graph.graph.nodes())[self.final_hub])\n",
    "                    route_to_final_hub=route[:index_in_route]\n",
    "                    print(route_to_final_hub)\n",
    "                    print(route)\n",
    "                    print(self.final_hub)\n",
    "                    route_travel_time_to_final_hub = ox.utils_graph.get_route_edge_attributes(self.graph.graph,route_to_final_hub,attribute='travel_time')\n",
    "                    step_duration = sum(route_travel_time_to_final_hub)\n",
    "\n",
    "                else:\n",
    "                    self.position = list(self.graph.graph.nodes()).index(selected_trip['target_node'])\n",
    "                    route_travel_time = ox.utils_graph.get_route_edge_attributes(self.graph.graph,selected_trip['route'],attribute='travel_time')\n",
    "                    step_duration = sum(route_travel_time)\n",
    "                \n",
    "                # Increase global time state by travelled time (does not include waiting yet, in this case it should be +xx seconds)\n",
    "                self.time = selected_trip['departure_time']\n",
    "\n",
    "                # Instead of cumulating trip duration here we return travel_time \n",
    "                # self.total_travel_time += timedelta(seconds=travel_time)\n",
    "\n",
    "            self.time += timedelta(seconds=step_duration)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        \n",
    "\n",
    "        return self.position, self.reward(),  self.isDone(), {}\n",
    "\n",
    "    def availableActions(self):\n",
    "        \"\"\" Returns the available actions at the current position. Uses a simplified action space with moves to all direct neighbors allowed.\n",
    "\n",
    "        Returns:\n",
    "            list: list of nodeIds of direct neighbors\n",
    "        \"\"\"\n",
    "        rides = list(self.availableTrips())\n",
    "        return rides\n",
    "\n",
    "    def availableTrips(self):\n",
    "        \"\"\" Returns a list of all available trips at the current node and within the next 5 minutes. Includes the time of departure from the current node as well as the target node of the trip.\n",
    "\n",
    "        Returns:\n",
    "            list: [departure_time,target_node]\n",
    "        \"\"\"\n",
    "        position=list(self.graph.graph.nodes())[self.start_hub]\n",
    "        position_str=str(list(self.graph.graph.nodes())[self.start_hub])\n",
    "        start_timestamp=self.time\n",
    "        time_window=5\n",
    "        end_timestamp = self.time + timedelta(minutes=time_window)\n",
    "        grid=self.graph.trips\n",
    "        list_trips=[]\n",
    "        paths=grid['node_timestamps']\n",
    "        \n",
    "        for index in range(len(paths)):\n",
    "            dict = grid['node_timestamps'][index]\n",
    "            for tupel_position in dict:\n",
    "                position_timestamp= datetime.strptime(str(dict[tupel_position]), \"%Y-%m-%d %H:%M:%S\")\n",
    "                inTimeframe = start_timestamp <= position_timestamp and end_timestamp >= position_timestamp\n",
    "                startsInCurrentPosition = str(tupel_position) == position_str\n",
    "                trip_target_node = grid['dropoff_node'][index]\n",
    "                isNotFinalNode = str(tupel_position) != str(trip_target_node)\n",
    "                \n",
    "                if startsInCurrentPosition and inTimeframe and isNotFinalNode:\n",
    "                    route = grid['route'][index]\n",
    "                    index_in_route = route.index(position)\n",
    "                    route_to_target_node=route[index_in_route::]\n",
    "                    trip = {'departure_time': position_timestamp, 'target_node': trip_target_node, 'route': route_to_target_node}\n",
    "                    list_trips.append(trip)\n",
    "        return list_trips\n",
    "\n",
    "    def validateAction(self, action):\n",
    "        return action < len(self.availableTrips()) + 1\n",
    "\n",
    "    def isDone(self):\n",
    "        if (self.count >= self.MAX_STEPS | self.position == self.final_hub ):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def reward(self): # TODO: extend function: should not return 0 reward if position is a second time on start_hub\n",
    "        \n",
    "        if self.isDone():\n",
    "            return 10\n",
    "        elif self.position == self.start_hub: \n",
    "            return 0\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def render(self, visualize_actionspace: bool = False):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            visualize_actionspace (bool, optional): _description_. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        current_pos_x = self.graph.nodes[list(self.graph.graph.nodes())[self.position]]['x']\n",
    "        current_pos_y = self.graph.nodes[list(self.graph.graph.nodes())[self.position]]['y']\n",
    "        final_hub_x = self.graph.nodes[list(self.graph.graph.nodes())[self.final_hub]]['x']\n",
    "        final_hub_y = self.graph.nodes[list(self.graph.graph.nodes())[self.final_hub]]['y']\n",
    "        start_hub_x = self.graph.nodes[list(self.graph.graph.nodes())[self.start_hub]]['x']\n",
    "        start_hub_y = self.graph.nodes[list(self.graph.graph.nodes())[self.start_hub]]['y']\n",
    "\n",
    "        # Create plot\n",
    "        plot = ox.plot_graph_folium(self.graph,fit_bounds=True, weight=2, color=\"#333333\")\n",
    "\n",
    "        # Place markers for start, final and current position\n",
    "        folium.Marker(location=[final_hub_y, final_hub_x], icon=folium.Icon(color='red', prefix='fa', icon='flag-checkered')).add_to(plot)\n",
    "        folium.Marker(location=[start_hub_y, start_hub_x], popup = f\"Pickup time: {self.pickup_time.strftime('%m/%d/%Y, %H:%M:%S')}\", icon=folium.Icon(color='lightblue', prefix='fa', icon='caret-right')).add_to(plot)\n",
    "        folium.Marker(location=[current_pos_y, current_pos_x], popup = f\"Current time: {self.time.strftime('%m/%d/%Y, %H:%M:%S')}\", icon=folium.Icon(color='lightgreen', prefix='fa',icon='cube')).add_to(plot)\n",
    "\n",
    "        if(visualize_actionspace):\n",
    "            for i, trip in enumerate(self.availableTrips()):\n",
    "                target_node_x = self.graph.nodes[trip['target_node']]['x']\n",
    "                target_node_y = self.graph.nodes[trip['target_node']]['y']\n",
    "                popup = \"%s: go to node %d\" % (i, trip['target_node'])\n",
    "                folium.Marker(location=[target_node_y, target_node_x], popup = popup, tooltip=str(i)).add_to(plot)\n",
    "\n",
    "        # Plot\n",
    "        pos_to_final = nx.shortest_path(self.graph, self.position, self.final_hub, weight=\"travel_time\")\n",
    "        if(not len(pos_to_final)< 2):\n",
    "            ox.plot_route_folium(G=self.graph,route=pos_to_final,route_map=plot)\n",
    "\n",
    "        return plot\n",
    "\n",
    "    def reset(self):\n",
    "        self.count = 0\n",
    "        self.final_hub = 3\n",
    "        self.start_hub = 6\n",
    "        self.position = 6\n",
    "        \n",
    "        pickup_day = 1\n",
    "        pickup_hour =  np.random.randint(24)\n",
    "        pickup_minute = np.random.randint(60)\n",
    "        self.pickup_time = datetime(2022,1,pickup_day,pickup_hour,pickup_minute,0)\n",
    "        \n",
    "        self.time = self.pickup_time\n",
    "        self.total_travel_time = 0\n",
    "\n",
    "\n",
    "        self.graph =StreetGraph('meinheim')\n",
    "        self.graph.trips = StreetGraph('meinheim').trips\n",
    "\n",
    "\n",
    "        return self.position\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GRAPH_NAME = 'meinheim'\n",
    "start_hub = 290333444\n",
    "final_hub = 280430536\n",
    "pickup_time=datetime(2022,1,1,1,1,0)\n",
    "\n",
    "streetgraph = StreetGraph(GRAPH_NAME)\n",
    "\n",
    "#env = Environment(streetgraph, start_hub, final_hub, pickup_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "#without ppo trainer\n",
    "def run_one_episode (env):\n",
    "    env.reset()\n",
    "    sum_reward = 0\n",
    "    for i in range(10):\n",
    "        action = env.action_space.sample()\n",
    "        state, reward, done, info = env.step(action)\n",
    "        sum_reward+=reward\n",
    "        #env.render()\n",
    "        if done:\n",
    "            print(sum_reward)\n",
    "            break\n",
    "    return sum_reward\n",
    "\n",
    "env=GraphEnv()\n",
    "for i in range(1):\n",
    "    run_one_episode (env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import gym\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents.ppo import PPOTrainer, DEFAULT_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-26 09:05:47,837\tINFO services.py:1374 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '127.0.0.1',\n",
       " 'raylet_ip_address': '127.0.0.1',\n",
       " 'redis_address': '127.0.0.1:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2022-03-26_09-05-45_858297_49231/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2022-03-26_09-05-45_858297_49231/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2022-03-26_09-05-45_858297_49231',\n",
       " 'metrics_export_port': 61472,\n",
       " 'gcs_address': '127.0.0.1:56159',\n",
       " 'node_id': '40a6ea0674f281283088bdb49620dd2fdd9362ab393a7379f4641c2e'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = DEFAULT_CONFIG.copy()\n",
    "trainer_config['num_workers'] = 1\n",
    "trainer_config[\"train_batch_size\"] = 400\n",
    "trainer_config[\"sgd_minibatch_size\"] = 64\n",
    "trainer_config[\"num_sgd_iter\"] = 10\n",
    "trainer_config[\"framework\"] = \"torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=50742)\u001b[0m 2022-03-26 10:29:37,986\tWARNING deprecation.py:45 -- DeprecationWarning: `rllib.env.remote_vector_env.RemoteVectorEnv` has been deprecated. Use `ray.rllib.env.remote_base_env.RemoteBaseEnv` instead. This will raise an error in the future!\n",
      "2022-03-26 10:29:38,062\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "trainer = PPOTrainer(trainer_config,GraphEnv )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_root = \"tmp/ppo/gridworld\"\n",
    "shutil.rmtree(checkpoint_root, ignore_errors=True, onerror=None)   # clean up old runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/Users/agnieszkalenart/Documents/mannheim/team_projekt/ines-autonomous-dispatching-1/rl/env/test_env.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/agnieszkalenart/Documents/mannheim/team_projekt/ines-autonomous-dispatching-1/rl/env/test_env.ipynb#ch0000008?line=2'>3</a>\u001b[0m episode_json \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/agnieszkalenart/Documents/mannheim/team_projekt/ines-autonomous-dispatching-1/rl/env/test_env.ipynb#ch0000008?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/agnieszkalenart/Documents/mannheim/team_projekt/ines-autonomous-dispatching-1/rl/env/test_env.ipynb#ch0000008?line=5'>6</a>\u001b[0m     result \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/agnieszkalenart/Documents/mannheim/team_projekt/ines-autonomous-dispatching-1/rl/env/test_env.ipynb#ch0000008?line=6'>7</a>\u001b[0m     results\u001b[39m.\u001b[39mappend(result)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/agnieszkalenart/Documents/mannheim/team_projekt/ines-autonomous-dispatching-1/rl/env/test_env.ipynb#ch0000008?line=8'>9</a>\u001b[0m     episode \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m: n, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/agnieszkalenart/Documents/mannheim/team_projekt/ines-autonomous-dispatching-1/rl/env/test_env.ipynb#ch0000008?line=9'>10</a>\u001b[0m                \u001b[39m'\u001b[39m\u001b[39mepisode_reward_min\u001b[39m\u001b[39m'\u001b[39m: result[\u001b[39m'\u001b[39m\u001b[39mepisode_reward_min\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/agnieszkalenart/Documents/mannheim/team_projekt/ines-autonomous-dispatching-1/rl/env/test_env.ipynb#ch0000008?line=10'>11</a>\u001b[0m                \u001b[39m'\u001b[39m\u001b[39mepisode_reward_mean\u001b[39m\u001b[39m'\u001b[39m: result[\u001b[39m'\u001b[39m\u001b[39mepisode_reward_mean\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/agnieszkalenart/Documents/mannheim/team_projekt/ines-autonomous-dispatching-1/rl/env/test_env.ipynb#ch0000008?line=11'>12</a>\u001b[0m                \u001b[39m'\u001b[39m\u001b[39mepisode_reward_max\u001b[39m\u001b[39m'\u001b[39m: result[\u001b[39m'\u001b[39m\u001b[39mepisode_reward_max\u001b[39m\u001b[39m'\u001b[39m],  \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/agnieszkalenart/Documents/mannheim/team_projekt/ines-autonomous-dispatching-1/rl/env/test_env.ipynb#ch0000008?line=12'>13</a>\u001b[0m                \u001b[39m'\u001b[39m\u001b[39mepisode_len_mean\u001b[39m\u001b[39m'\u001b[39m: result[\u001b[39m'\u001b[39m\u001b[39mepisode_len_mean\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/agnieszkalenart/Documents/mannheim/team_projekt/ines-autonomous-dispatching-1/rl/env/test_env.ipynb#ch0000008?line=13'>14</a>\u001b[0m               }\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py:315\u001b[0m, in \u001b[0;36mTrainable.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py?line=274'>275</a>\u001b[0m \u001b[39m\"\"\"Runs one logical iteration of training.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py?line=275'>276</a>\u001b[0m \n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py?line=276'>277</a>\u001b[0m \u001b[39mCalls ``step()`` internally. Subclasses should override ``step()``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py?line=311'>312</a>\u001b[0m \u001b[39m    A dict that describes training progress.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py?line=312'>313</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py?line=313'>314</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py?line=314'>315</a>\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py?line=315'>316</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mdict\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39mstep() needs to return a dict.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/tune/trainable.py?line=317'>318</a>\u001b[0m \u001b[39m# We do not modify internal state nor update this result if duplicate.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py:982\u001b[0m, in \u001b[0;36mTrainer.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=978'>979</a>\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=979'>980</a>\u001b[0m             \u001b[39m# Allow logs messages to propagate.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=980'>981</a>\u001b[0m             time\u001b[39m.\u001b[39msleep(\u001b[39m0.5\u001b[39m)\n\u001b[0;32m--> <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=981'>982</a>\u001b[0m             \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=983'>984</a>\u001b[0m result \u001b[39m=\u001b[39m step_attempt_results\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=985'>986</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mworkers\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworkers, WorkerSet):\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=986'>987</a>\u001b[0m     \u001b[39m# Sync filters on workers.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py:963\u001b[0m, in \u001b[0;36mTrainer.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=959'>960</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m step_ctx\u001b[39m.\u001b[39mshould_stop(step_attempt_results):\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=960'>961</a>\u001b[0m     \u001b[39m# Try to train one step.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=961'>962</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=962'>963</a>\u001b[0m         step_attempt_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_attempt()\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=963'>964</a>\u001b[0m     \u001b[39m# @ray.remote RolloutWorker failure.\u001b[39;00m\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=964'>965</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m RayError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=965'>966</a>\u001b[0m         \u001b[39m# Try to recover w/o the failed worker.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py:1042\u001b[0m, in \u001b[0;36mTrainer.step_attempt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1039'>1040</a>\u001b[0m \u001b[39m# No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1040'>1041</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evaluate_this_iter:\n\u001b[0;32m-> <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1041'>1042</a>\u001b[0m     step_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_plan_or_training_iteration_fn()\n\u001b[1;32m   <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1042'>1043</a>\u001b[0m \u001b[39m# We have to evaluate in this training iteration.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1043'>1044</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1044'>1045</a>\u001b[0m     \u001b[39m# No parallelism.\u001b[39;00m\n\u001b[1;32m   <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1045'>1046</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mevaluation_parallel_to_training\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py:1962\u001b[0m, in \u001b[0;36mTrainer._exec_plan_or_training_iteration_fn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1959'>1960</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_iteration()\n\u001b[1;32m   <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1960'>1961</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1961'>1962</a>\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_exec_impl)\n\u001b[1;32m   <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/rllib/agents/trainer.py?line=1962'>1963</a>\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/util/iter.py:756\u001b[0m, in \u001b[0;36mLocalIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/util/iter.py?line=753'>754</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/util/iter.py?line=754'>755</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_once()\n\u001b[0;32m--> <a href='file:///~/miniconda3/lib/python3.8/site-packages/ray/util/iter.py?line=755'>756</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuilt_iterator)\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "episode_data = []\n",
    "episode_json = []\n",
    "\n",
    "for n in range(1):\n",
    "    result = trainer.train()\n",
    "    results.append(result)\n",
    "    \n",
    "    episode = {'n': n, \n",
    "               'episode_reward_min': result['episode_reward_min'], \n",
    "               'episode_reward_mean': result['episode_reward_mean'], \n",
    "               'episode_reward_max': result['episode_reward_max'],  \n",
    "               'episode_len_mean': result['episode_len_mean']\n",
    "              }\n",
    "    \n",
    "    episode_data.append(episode)\n",
    "    episode_json.append(json.dumps(episode))\n",
    "    file_name = trainer.save(checkpoint_root)\n",
    "    \n",
    "    print(f'{n+1:3d}: Min/Mean/Max reward: {result[\"episode_reward_min\"]:8.4f}/{result[\"episode_reward_mean\"]:8.4f}/{result[\"episode_reward_max\"]:8.4f}, len mean: {result[\"episode_len_mean\"]:8.4f}. Checkpoint saved to {file_name}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "659ff4560fff501816ab5557c69e2236a8a93dda2d0369456c34960305f58737"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
